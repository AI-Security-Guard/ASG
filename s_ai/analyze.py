import subprocess, shutil
import os
import cv2
import json
import sqlite3
import numpy as np
from collections import deque
from typing import List, Dict, Any
import torch
from torchvision import transforms
from models.models import DFGAR as DFWSGARModel
from utils.utils import (
    fuse_tokens_spatial,
    heatmap_to_point,
    smooth_point,
    calculate_box_coordinates,
    TOP_PCT,
    ALPHA_HM,
    ALPHA_PT,
    JUMP_MAX_PIX,
    JUMP_BLEND,
    BOX_FRAC_W,
    BOX_FRAC_H,
)
from models.analysis import Clip
from database import db

# ì „ì—­ ì„¤ì •/ìƒìˆ˜
CLASS_NAMES: List[str] = ["normal", "assault"]

RESIZE_W, RESIZE_H = 640, 360
STRIDE = 6
TEMP = 2.0
PROB_THRESH = 0.80
MARGIN_THRESH = 1.00
USE_EMA = True
EMA_ALPHA_P = 0.15
EMA_RESET_EACH_WINDOW = False

MODEL_PATH = "model/best_model.pth"
THRESHOLD_PATH = "model/best_threshold.txt"

# ë””ìŠ¤í¬ ì €ì¥ í´ë”
ANNOTATED_DIR = "analyzed_videos"  # ì£¼ì„(ë°•ìŠ¤) ì˜ìƒ
CLIPS_DIR = "event_clips"  # ë¹„ì •ìƒ êµ¬ê°„ í´ë¦½ ëª¨ìŒ (ì£¼ì„ì˜ìƒì—ì„œ ì¦‰ì‹œ ì¶”ì¶œ, 1íŒ¨ìŠ¤)
os.makedirs(ANNOTATED_DIR, exist_ok=True)
os.makedirs(CLIPS_DIR, exist_ok=True)

# DB (SQLite) â€” payloadì— ìµœì†Œ ë°ì´í„° + ì§„í–‰ë¥ (progress) í¬í•¨
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "jobs.db")


# ì¸ë„¤ì¼ ê´€ë ¨
THUMB_DIR = "thumbnails"
os.makedirs(THUMB_DIR, exist_ok=True)


# DB ìœ í‹¸ (ìµœì†Œ í•„ë“œ + progress)
def _db():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False, timeout=5.0)
    conn.execute("PRAGMA journal_mode=WAL;")
    conn.execute("PRAGMA synchronous=NORMAL;")
    conn.execute("PRAGMA busy_timeout=5000;")
    # âŒ ì—¬ê¸°ì„œ í…Œì´ë¸”ì„ ì„ì˜ ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤!
    # SQLAlchemyê°€ ë§Œë“  ê¸°ì¡´ jobs ìŠ¤í‚¤ë§ˆë§Œ ì‚¬ìš©í•œë‹¤.
    return conn


_DB_CONN = _db()


def _encode_h264_faststart(in_path: str):
    """
    ì–´ë–¤ ì»¨í…Œì´ë„ˆ/ì½”ë±ìœ¼ë¡œ ë‚˜ì˜¤ë“  ê°„ì—,
    H.264 + yuv420p + main@L4.0 ë¡œ íŠ¸ëœìŠ¤ì½”ë”©í•˜ê³  faststartê¹Œì§€ ì ìš©.
    ê²°ê³¼ëŠ” ì›ë³¸ ê²½ë¡œë¥¼ ë®ì–´ì“´ë‹¤.
    """
    try:
        if not in_path or not os.path.exists(in_path):
            return
        if not shutil.which("ffmpeg"):
            return  # ffmpeg ì—†ìœ¼ë©´ ì¡°ìš©íˆ íŒ¨ìŠ¤

        # ì¶œë ¥ ì„ì‹œ mp4 ê²½ë¡œ
        base, _ = os.path.splitext(in_path)
        out_tmp = base + "_avc.mp4"

        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            in_path,
            "-c:v",
            "libx264",
            "-pix_fmt",
            "yuv420p",
            "-profile:v",
            "main",
            "-level",
            "4.0",
            "-movflags",
            "+faststart",
            "-an",  # ì˜¤ë””ì˜¤ í•„ìš”í•˜ë©´ ì´ ì¤„ ì œê±°
            out_tmp,
        ]
        subprocess.run(
            cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )

        # ì„±ê³µí•˜ë©´ ì›ë³¸ ë°”ê¾¸ê¸°
        os.replace(
            out_tmp, in_path if in_path.lower().endswith(".mp4") else (base + ".mp4")
        )
        # í™•ì¥ìê°€ .aviì˜€ë‹¤ë©´ .mp4ë¡œ ë°”ë€Œì—ˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜
    except Exception:
        pass


def _faststart_remux(in_path: str):
    """mp4 ì»¨í…Œì´ë„ˆ ë©”íƒ€ë°ì´í„°(moov)ë¥¼ ì•ìª½ìœ¼ë¡œ ì˜®ê²¨ ìŠ¤íŠ¸ë¦¬ë°/ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ë³´"""
    try:
        if not in_path or not in_path.lower().endswith(".mp4"):
            return
        if not shutil.which("ffmpeg"):
            return  # ffmpeg ì—†ìœ¼ë©´ ì¡°ìš©íˆ íŒ¨ìŠ¤ (í¬ë˜ì‹œ ë°©ì§€)

        tmp = in_path[:-4] + "_fs.mp4"
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            in_path,
            "-c",
            "copy",
            "-movflags",
            "+faststart",
            tmp,
        ]
        subprocess.run(
            cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )

        # ì„±ê³µí•˜ë©´ ì›ë³¸ êµì²´
        os.replace(tmp, in_path)
    except Exception:
        # ì‹¤íŒ¨í•´ë„ ë¶„ì„ íë¦„ì€ ìœ ì§€
        pass


# analyze.py ìƒë‹¨ DB ìœ í‹¸ ê·¼ì²˜ì— ì¶”ê°€
def _get_jobs_columns():
    cur = _DB_CONN.execute("PRAGMA table_info(jobs);")
    return {row[1] for row in cur.fetchall()}


def db_upsert_job(job: Dict[str, Any]):
    cols = _get_jobs_columns()
    cur = _DB_CONN.cursor()

    if "username" in cols and job.get("job_id") and not job.get("username"):
        try:
            r = cur.execute(
                "SELECT username FROM jobs WHERE job_id = ?", (job["job_id"],)
            ).fetchone()
            if r and r[0]:
                job["username"] = r[0]
        except Exception:
            pass

    insert_cols = ["job_id"]
    insert_vals = [job.get("job_id")]
    update_sets = []

    def add(col: str, val: Any, *, skip_none: bool = False):
        if col not in cols:
            return
        if skip_none and val is None:
            return
        insert_cols.append(col)
        insert_vals.append(val)
        update_sets.append(f"{col}=excluded.{col}")

    # ì„ íƒì ìœ¼ë¡œ ì¡´ì¬í•  ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ë“¤ë§Œ ë°˜ì˜
    add("video_path", job.get("video_path") or "")
    add("status", job.get("status") or "running")

    pr = job.get("progress")
    add("progress", float(pr) if isinstance(pr, (int, float)) else 0.0)

    # results ì¹¼ëŸ¼ì´ ìˆë‹¤ë©´ JSON ë¬¸ìì—´ë¡œ ì €ì¥(ì—†ìœ¼ë©´ skip)
    if "results" in cols:
        res = job.get("results")
        res_str = json.dumps(res, ensure_ascii=False) if res is not None else None
        insert_cols.append("results")
        insert_vals.append(res_str)
        update_sets.append("results=excluded.results")

    # annotated_video / message ê°™ì€ ì¹¼ëŸ¼ë„ ìˆìœ¼ë©´ ë°˜ì˜
    if "annotated_video" in cols:
        add("annotated_video", job.get("annotated_video"), skip_none=True)
    if "message" in cols:
        add("message", job.get("message"), skip_none=True)
    add("username", job.get("username"), skip_none=True)
    placeholders = ", ".join(["?"] * len(insert_cols))
    columns_csv = ", ".join(insert_cols)

    if update_sets:
        q = f"""
            INSERT INTO jobs ({columns_csv})
            VALUES ({placeholders})
            ON CONFLICT(job_id) DO UPDATE SET {", ".join(update_sets)}
        """
    else:
        # í˜¹ì‹œ ì •ë§ job_id ì™¸ì— ê°±ì‹ í•  ì¹¼ëŸ¼ì´ í•˜ë‚˜ë„ ì—†ë‹¤ë©´â€¦
        q = f"""
            INSERT INTO jobs ({columns_csv})
            VALUES ({placeholders})
            ON CONFLICT(job_id) DO NOTHING
        """

    cur.execute(q, insert_vals)
    _DB_CONN.commit()


def db_get_job(job_id: str) -> Dict[str, Any] | None:
    cur = _DB_CONN.cursor()
    cols = _get_jobs_columns()
    # ì½ì„ ì¹¼ëŸ¼ë§Œ êµ¬ì„±
    wanted = [
        c
        for c in [
            "job_id",
            "video_path",
            "status",
            "progress",
            "results",
            "annotated_video",
            "message",
            "thumbnail",
        ]
        if c in cols
    ]
    if not wanted:
        return None
    cur.execute(f"SELECT {', '.join(wanted)} FROM jobs WHERE job_id = ?", (job_id,))
    row = cur.fetchone()
    if not row:
        return None
    data = dict(zip(wanted, row))
    # resultsê°€ ë¬¸ìì—´ì´ë©´ JSON ë””ì½”ë“œ ì‹œë„
    if "results" in data and isinstance(data["results"], str):
        try:
            data["results"] = json.loads(data["results"])
        except Exception:
            pass
    return data


# ìœ í‹¸
def idx_of(name: str) -> int:
    try:
        return CLASS_NAMES.index(name)
    except ValueError:
        return -1


def build_args_for_model():
    class Args:
        def __init__(self):
            self.dataset = "optimized_dataset"
            self.num_activities = 2
            self.num_frame = 18
            self.hidden_dim = 256
            self.num_tokens = 6
            self.nheads_agg = 4
            self.drop_rate = 0.1
            self.position_embedding = "sine"
            self.dilation = False
            self.nheads = 8
            self.ffn_dim = 512
            self.enc_layers = 1
            self.pre_norm = False
            self.backbone = "resnet18"
            self.motion = True
            self.motion_layer = 3
            self.multi_corr = True
            self.corr_dim = 64
            self.neighbor_size = 2
            self.task_mode = "group_activity"

    return Args()


def frames_to_tensor_batch(frames_bgr, device):
    xt = [
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(
            transforms.functional.to_tensor(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))
        )
        for f in frames_bgr
    ]
    x = torch.stack(xt, dim=0)[None].to(device)  # [1,T,3,H,W]
    return x


def _format_time_hhmmss(seconds: float) -> str:
    if seconds < 0:
        seconds = 0
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(round(seconds % 60))
    return f"{h:02d}:{m:02d}:{s:02d}"


# ë””ë°”ì´ìŠ¤/ëª¨ë¸ ë¡œë“œ
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu") #GPU ì‚¬ìš©ì‹œ í™œì„±í™” ( CPU ì‚¬ìš©ì‹œ ì£¼ì„ ì²˜ë¦¬ í•„ìˆ˜! )
device = torch.device("cpu")  # CPU ì‚¬ìš©ì‹œ í™œì„±í™”( GPU ì‚¬ìš©ì‹œ ì£¼ì„ ì²˜ë¦¬ í•„ìˆ˜! )

_args = build_args_for_model()
model = DFWSGARModel(_args).to(device).eval()

if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"Model file not found: {MODEL_PATH}")

ck = torch.load(MODEL_PATH, map_location=device)
if not (isinstance(ck, dict) and "state_dict" in ck):
    raise KeyError(
        f"Expected checkpoint with key 'state_dict', got keys={list(ck.keys()) if isinstance(ck, dict) else type(ck)}"
    )
sd = {(k[7:] if k.startswith("module.") else k): v for k, v in ck["state_dict"].items()}
_ = model.load_state_dict(sd, strict=False)

prob_threshold: float = float(PROB_THRESH)
if os.path.exists(THRESHOLD_PATH):
    try:
        with open(THRESHOLD_PATH, "r") as f:
            prob_threshold = float(f.read().strip())
    except Exception:
        pass

torch.set_grad_enabled(False)


# ì‘ì—… ìƒíƒœ (ë©”ëª¨ë¦¬ ìµœì†Œ)
processing_jobs: Dict[str, Dict[str, Any]] = {}


# 1íŒ¨ìŠ¤ ë¶„ì„ + ì£¼ì„ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° + í´ë¦½ ë™ì‹œ ìƒì„±
def analyze_video_pure(job_id: str, video_path: str, on_progress=None):
    current_clip_path = None
    try:
        processing_jobs[job_id] = {
            "job_id": job_id,
            "status": "running",
            "progress": 0.0,
            "results": None,
            "video_path": video_path,
            "annotated_video": None,
        }
        db_upsert_job(processing_jobs[job_id])

        threshold = prob_threshold

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise RuntimeError(f"ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
        orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        # ì£¼ì„ ì˜ìƒ writer (ì›ë³¸ í•´ìƒë„)
        base_name = os.path.splitext(os.path.basename(video_path))[0]

        # âœ… ì•ˆì „í•œ VideoWriter ìƒì„± í•¨ìˆ˜ ì •ì˜
        from pathlib import Path

        # âœ… ì•ˆì „í•œ VideoWriter ìƒì„± í•¨ìˆ˜
        def _safe_video_writer(
            input_path, out_dir="analyzed_videos", fps_val=30.0, size=(640, 360)
        ):
            out_dir_path = Path(out_dir).resolve()
            out_dir_path.mkdir(parents=True, exist_ok=True)

            stem = Path(input_path).stem
            mp4_path = out_dir_path / f"{stem}_analyze.mp4"
            avi_path = out_dir_path / f"{stem}_analyze.avi"

            tried = []
            for fourcc_str, path in [("mp4v", mp4_path), ("avc1", mp4_path)]:
                fourcc = cv2.VideoWriter_fourcc(*fourcc_str)
                writer = cv2.VideoWriter(str(path), fourcc, fps_val, size)
                tried.append((fourcc_str, str(path)))
                if writer.isOpened():
                    return writer, str(path)

            for fourcc_str, path in [("MJPG", avi_path), ("XVID", avi_path)]:
                fourcc = cv2.VideoWriter_fourcc(*fourcc_str)
                writer = cv2.VideoWriter(str(path), fourcc, fps_val, size)
                tried.append((fourcc_str, str(path)))
                if writer.isOpened():
                    return writer, str(path)

            raise RuntimeError(
                "Failed to open VideoWriter for any codec: " + str(tried)
            )

        # âœ… í´ë¦½ìš© VideoWriter ì˜¤í”„ë„ˆ (mp4 â†’ avi ìˆœì„œ)
        def _open_clip_writer(
            base_name: str, clip_idx: int, fps_val: float, size: tuple[int, int]
        ):
            out_dir_path = Path(CLIPS_DIR).resolve()
            out_dir_path.mkdir(parents=True, exist_ok=True)

            # 1) mp4 ì‹œë„
            name_mp4 = f"{base_name}_clip{clip_idx}.mp4"
            path_mp4 = out_dir_path / name_mp4
            for fourcc_str in ["mp4v", "avc1"]:
                w = cv2.VideoWriter(
                    str(path_mp4), cv2.VideoWriter_fourcc(*fourcc_str), fps_val, size
                )
                if w.isOpened():
                    return w, str(path_mp4), name_mp4

            # 2) avi í´ë°±
            name_avi = f"{base_name}_clip{clip_idx}.avi"
            path_avi = out_dir_path / name_avi
            for fourcc_str in ["MJPG", "XVID"]:
                w = cv2.VideoWriter(
                    str(path_avi), cv2.VideoWriter_fourcc(*fourcc_str), fps_val, size
                )
                if w.isOpened():
                    return w, str(path_avi), name_avi

            raise RuntimeError("Failed to open clip writer for any codec")

        # FPS ë³´ì •
        if fps <= 0 or fps is None:
            fps = 30.0

        # âœ… ì—¬ê¸°ì„œ ì•ˆì „í•˜ê²Œ VideoWriter ìƒì„±
        annot_writer, annotated_path = _safe_video_writer(
            video_path, ANNOTATED_DIR, fps, (orig_w, orig_h)
        )

        annotated_path = annotated_path.replace("\\", "/")

        # 2ì´ˆ ë³‘í•©ìš© tol í”„ë ˆì„ ìˆ˜
        tol_frames = int(round((fps if fps > 0 else 30.0) * 2.0))

        # ìŠ¬ë¼ì´ë”© ë²„í¼ (ì›ë³¸/ë¦¬ì‚¬ì´ì¦ˆ ë‘˜ ë‹¤)
        buf_small = deque(maxlen=_args.num_frame)  # 640x360
        buf_orig = deque(maxlen=_args.num_frame)  # ì›ë³¸ í•´ìƒë„

        # ì´ˆê¸° ë²„í¼ ì±„ìš°ê¸°
        while len(buf_small) < _args.num_frame:
            ok, fr = cap.read()
            if not ok:
                break
            fr_orig = fr  # ì›ë³¸ í”„ë ˆì„
            fr_small = cv2.resize(
                fr_orig, (RESIZE_W, RESIZE_H), interpolation=cv2.INTER_AREA
            )
            buf_small.append(fr_small)
            buf_orig.append(fr_orig)

        # í† í° ìœµí•© ê¸°ë°˜ ë‹¨ì¼ ë°•ìŠ¤ ì¶”ì ìš© ìƒíƒœ
        prev_pt = None
        hm_ema = None

        frame_base_idx = 0
        p_assault_ema = None

        # ì§„í–‰ë¥  ì €ì¥ìš©
        written_frames = 0
        last_saved_progress = -1.0  # DB ì“°ê¸° ë¹ˆë„ ì¤„ì´ê¸°

        # í´ë¦½ ìƒíƒœë¨¸ì‹  (1íŒ¨ìŠ¤)
        clips_meta: List[Dict[str, Any]] = []
        clip_id = 0
        active_clip = None  # cv2.VideoWriter | None
        active_class = None  # í˜„ì¬ ë…¹í™”ì¤‘ í´ë˜ìŠ¤ëª…
        in_gap = False
        gap_buf = []  # ì£¼ì„ í”„ë ˆì„ ì„ì‹œ ë³´ê´€ (RAM)
        start_bbox_orig = None  # ìƒˆ í´ë¦½ ì‹œì‘ bbox(ì›ë³¸ ì¢Œí‘œ)

        def _open_clip(start_time_sec: float, frame_for_thumb, box_for_thumb):
            nonlocal clip_id, active_clip, current_clip_path
            clip_id += 1

            # âœ… fourcc ì—†ì´ ì•ˆì „ ìƒì„±ê¸° ì‚¬ìš©
            active_clip, clip_abs_path, clip_name = _open_clip_writer(
                base_name, clip_id, fps, (orig_w, orig_h)
            )
            clip_abs_path = clip_abs_path.replace("\\", "/")  # í”„ë¡ íŠ¸ í˜¸í™˜
            current_clip_path = clip_abs_path
            # per-clip ì¸ë„¤ì¼ ìƒì„±
            thumb_path = os.path.join(THUMB_DIR, f"{base_name}_clip{clip_id}_thumb.jpg")
            try:
                if box_for_thumb:
                    X1, Y1, X2, Y2 = box_for_thumb
                    X1 = max(0, min(X1, orig_w - 1))
                    X2 = max(0, min(X2, orig_w - 1))
                    Y1 = max(0, min(Y1, orig_h - 1))
                    Y2 = max(0, min(Y2, orig_h - 1))
                    crop = frame_for_thumb[Y1:Y2, X1:X2].copy()
                    img_for_thumb = crop if crop.size else frame_for_thumb
                else:
                    img_for_thumb = frame_for_thumb

                ok = cv2.imwrite(
                    thumb_path, img_for_thumb, [cv2.IMWRITE_JPEG_QUALITY, 90]
                )
                thumb_path = thumb_path.replace("\\", "/") if ok else None
            except Exception:
                thumb_path = None

            # ê²°ê³¼ ë©”íƒ€ (class_name/thumbnail í¬í•¨)
            clips_meta.append(
                {
                    "clip_id": clip_id,
                    "class_name": active_class,
                    "start_time": _format_time_hhmmss(start_time_sec),
                    "start_bbox": start_bbox_orig,  # [x1,y1,x2,y2] or None
                    "clip_name": clip_name,  # âœ… ìƒˆ ì´ë¦„ ì‚¬ìš©
                    "clip_path": clip_abs_path,  # âœ… ì ˆëŒ€ê²½ë¡œ/ìŠ¬ë˜ì‹œ ì •ë¦¬ëœ ê²½ë¡œ
                    "thumbnail": thumb_path,
                }
            )

        def _close_clip():
            nonlocal active_clip, in_gap, gap_buf, start_bbox_orig, current_clip_path  # â† current_clip_path ì¶”ê°€
            if active_clip and active_clip.isOpened():
                active_clip.release()
                try:
                    _faststart_remux(current_clip_path)
                    _encode_h264_faststart(current_clip_path)
                except Exception:
                    pass
            active_clip = None
            current_clip_path = None
            in_gap = False
            gap_buf.clear()
            start_bbox_orig = None

        # ì–´ì„¤íŠ¸ ë§ˆìŠ¤í¬ (ì°½ íŒì • ê¸°ë°˜ í”„ë ˆì„ ë§ˆìŠ¤í¬)
        assault_mask = np.zeros(max(total_frames, 1), dtype=np.uint8)

        while len(buf_small) == _args.num_frame:
            # EMA ì´ˆê¸°í™” ì˜µì…˜
            if EMA_RESET_EACH_WINDOW:
                p_assault_ema = None

            frames_small = list(buf_small)
            frames_orig = list(buf_orig)

            # ëª¨ë¸ ì…ë ¥/ì¶”ë¡ 
            x_bthwc = frames_to_tensor_batch(frames_small, device)  # [1,T,3,H,W]
            x_btchw = x_bthwc[0]  # [T,3,H,W]

            logits = model(x_bthwc) / TEMP
            probs = torch.softmax(logits, dim=1)[0].detach().cpu().numpy()
            pred_idx = int(np.argmax(probs))
            top1_name = (
                CLASS_NAMES[pred_idx]
                if 0 <= pred_idx < len(CLASS_NAMES)
                else str(pred_idx)
            )
            top1_prob = float(probs[pred_idx])

            aid = idx_of("assault")
            p_assault_raw = float(probs[aid]) if 0 <= aid < len(probs) else 0.0

            # margin
            if aid >= 0 and logits.shape[1] > 1 and aid < logits.shape[1]:
                logit_vec = logits[0]
                if logit_vec.shape[0] > 1:
                    other_left = logit_vec[:aid]
                    other_right = logit_vec[aid + 1 :]
                    candidates = []
                    if other_left.numel() > 0:
                        candidates.append(torch.max(other_left).item())
                    if other_right.numel() > 0:
                        candidates.append(torch.max(other_right).item())
                    best_other = max(candidates) if candidates else 0.0
                else:
                    best_other = 0.0
                margin = float(logit_vec[aid].item() - best_other)
            else:
                margin = 0.0

            # EMA
            p_assault_ema = (
                p_assault_raw
                if (p_assault_ema is None or not USE_EMA)
                else (1 - EMA_ALPHA_P) * p_assault_ema + EMA_ALPHA_P * p_assault_raw
            )

            # ì°½ íŒì •
            is_assault_base = (
                (aid >= 0)
                and (p_assault_ema >= threshold)
                and (margin >= MARGIN_THRESH)
            )

            # ë°±ë³¸/ì–´í…ì…˜ â†’ ë‹¨ì¼ íˆíŠ¸ë§µ(fuse)
            src, pos = model.backbone(x_btchw)  # [T,C,oh,ow], [T,C,oh,ow]
            T_, C_, oh, ow = src.shape
            src_proj = model.input_proj(src)  # [T,D,oh,ow]
            _, att = model.token_encoder(src_proj, None, model.query_embed.weight, pos)
            if att.dim() == 5:
                att = att[0]

            # ì–´ë–¤ í”„ë ˆì„ì„ "ì´ë²ˆ ì°½ì—ì„œ ì‹¤ì œë¡œ ì“¸ì§€" (ì¤‘ë³µ ë°©ì§€)
            write_range = range(T_) if frame_base_idx == 0 else range(T_ - STRIDE, T_)

            # ìŠ¤ì¼€ì¼ íŒ©í„° (640x360 â†’ ì›ë³¸)
            sx = orig_w / float(RESIZE_W)
            sy = orig_h / float(RESIZE_H)

            for t in range(T_):
                fidx = frame_base_idx + t
                # assault_mask í¬ê¸° ì•ˆì „
                if fidx >= len(assault_mask):
                    assault_mask = np.pad(
                        assault_mask,
                        (0, (fidx + 1 - len(assault_mask))),
                        constant_values=0,
                    )

                # ë‹¨ì¼ íˆíŠ¸ë§µ ìƒì„±
                if att.dim() == 3:  # [T,Q,HW]
                    att_t = att[t]  # [Q,HW]
                elif att.dim() == 4:  # [T,H,Q,K]
                    att_t = att[t]  # [H,Q,K]
                else:
                    raise RuntimeError(f"Unexpected att shape: {tuple(att.shape)}")

                p_map = fuse_tokens_spatial(att_t, oh, ow)
                p_up = cv2.resize(
                    p_map, (RESIZE_W, RESIZE_H), interpolation=cv2.INTER_LINEAR
                )
                p_up = np.clip(p_up, 0.0, 1.0)

                hm_ema = (
                    p_up.copy()
                    if hm_ema is None
                    else (1 - ALPHA_HM) * hm_ema + ALPHA_HM * p_up
                )
                cx, cy = heatmap_to_point(hm_ema, mode="centroid", top_pct=TOP_PCT)
                prev_pt = smooth_point(
                    prev_pt,
                    (cx, cy),
                    alpha=ALPHA_PT,
                    jump_max=JUMP_MAX_PIX,
                    jump_blend=JUMP_BLEND,
                )
                box_small = calculate_box_coordinates(
                    prev_pt, RESIZE_W, RESIZE_H, BOX_FRAC_W, BOX_FRAC_H
                )

                # ì°½ íŒì • ê²°ê³¼ë¥¼ í”„ë ˆì„ ë§ˆìŠ¤í¬ë¡œ í™•ì¥
                st, ed = frame_base_idx, frame_base_idx + _args.num_frame - 1
                if is_assault_base and st < len(assault_mask):
                    assault_mask[st : min(ed + 1, len(assault_mask))] = 1

                if t not in write_range:
                    continue  # ì´ë²ˆ ì°½ì—ì„œ ì´ í”„ë ˆì„ì€ ì´ë¯¸ ì“´ ì  ìˆìŒ

                # === ì—¬ê¸°ì„œë¶€í„° "í•œ ë²ˆë§Œ" ì“°ëŠ” ì„¹ì…˜ (ì£¼ì„ + í´ë¦½ ìƒíƒœë¨¸ì‹ ) ===
                # ì›ë³¸ í”„ë ˆì„ êº¼ë‚´ì„œ ë°•ìŠ¤ ê·¸ë ¤ ì£¼ì„ í”„ë ˆì„ ë§Œë“¤ê¸°
                frame_orig = frames_orig[t].copy()
                # positive ì—¬ë¶€: assault ë§ˆìŠ¤í¬ ë˜ëŠ” top-1ì´ normalì´ ì•„ë‹˜
                is_positive = bool(assault_mask[fidx]) or (
                    str(top1_name).lower() != "normal"
                )

                if is_positive and box_small:
                    x1, y1, x2, y2 = box_small
                    X1 = int(round(x1 * sx))
                    Y1 = int(round(y1 * sy))
                    X2 = int(round(x2 * sx))
                    Y2 = int(round(y2 * sy))
                    cv2.rectangle(frame_orig, (X1, Y1), (X2, Y2), (0, 0, 255), 2)
                    box_orig = [X1, Y1, X2, Y2]
                else:
                    box_orig = None

                # (A) ì£¼ì„ ì˜ìƒì— ë°”ë¡œ write
                annot_writer.write(frame_orig)
                written_frames += 1

                # (B) í´ë¦½ ìƒíƒœë¨¸ì‹  (2ì´ˆ ë³‘í•© ìœ ì§€)
                cls_name = top1_name

                if is_positive and active_clip is None:
                    active_class = cls_name
                    start_bbox_orig = box_orig
                    _open_clip(
                        start_time_sec=(fidx / fps if fps > 0 else 0.0),
                        frame_for_thumb=frame_orig,
                        box_for_thumb=box_orig,
                    )
                    active_clip.write(frame_orig)

                elif is_positive:
                    # ì´ë¯¸ ë…¹í™” ì¤‘ì¸ ìƒíƒœ
                    if in_gap:
                        # ê°™ì€ í´ë˜ìŠ¤ ë³µê·€ + gap â‰¤ tol â†’ ë²„í¼ flush + ì´ì–´ì“°ê¸°
                        if (
                            cls_name.lower() == active_class.lower()
                            and len(gap_buf) <= tol_frames
                        ):
                            for fr in gap_buf:
                                active_clip.write(fr)
                            gap_buf.clear()
                            in_gap = False
                            active_clip.write(frame_orig)
                        else:
                            # ë‹¤ë¥¸ í´ë˜ìŠ¤ or tol ì´ˆê³¼ â†’ ì´ì „ ì¢…ë£Œ í›„ ìƒˆë¡œ ì‹œì‘
                            _close_clip()
                            active_class = cls_name
                            start_bbox_orig = box_orig
                            _open_clip(
                                start_time_sec=(fidx / fps if fps > 0 else 0.0),
                                frame_for_thumb=frame_orig,
                                box_for_thumb=box_orig,
                            )
                            active_clip.write(frame_orig)
                    else:
                        # gap ì•„ë‹Œ ìƒíƒœì—ì„œ
                        if cls_name.lower() == active_class.lower():
                            active_clip.write(frame_orig)
                        else:
                            # í´ë˜ìŠ¤ ë³€ê²½ â†’ ì´ì „ ì¢…ë£Œ, ìƒˆë¡œ ì‹œì‘
                            _close_clip()
                            active_class = cls_name
                            start_bbox_orig = box_orig
                            _open_clip(
                                start_time_sec=(fidx / fps if fps > 0 else 0.0),
                                frame_for_thumb=frame_orig,
                                box_for_thumb=box_orig,
                            )
                            active_clip.write(frame_orig)

                else:
                    # ìŒì„± í”„ë ˆì„
                    if active_clip is not None:
                        # gap ì§„ì…/ìœ ì§€
                        if not in_gap:
                            in_gap = True
                            gap_buf = [frame_orig]
                        else:
                            gap_buf.append(frame_orig)
                            if len(gap_buf) > tol_frames:
                                # 2ì´ˆ ì´ˆê³¼ â†’ ì´ì „ í´ë¦½ ì¢…ë£Œ, ë²„í¼ íê¸°
                                _close_clip()

                # (C) ì§„í–‰ë¥  ì €ì¥ (DB write ë¹ˆë„ ì¤„ì—¬ì„œ ì—…ë°ì´íŠ¸)
                if total_frames > 0:
                    progress = min(99.0, (written_frames / total_frames) * 100.0)
                else:
                    # ğŸ¯ Fallback: í”„ë ˆì„ ìˆ˜ë¥¼ ì•Œ ìˆ˜ ì—†ì„ ë•ŒëŠ” ì¡°ê¸ˆì”©ì´ë¼ë„ ì „ì§„í•˜ë„ë¡
                    # ë„ˆë¬´ ëŠë¦¬ê²Œ ë³´ì´ì§€ ì•Šê²Œ ìµœì†Œ 0.5%ì”© ì¦ê°€ (ìƒí•œ 99%)
                    progress = min(
                        99.0,
                        (last_saved_progress if last_saved_progress >= 0 else 0.0)
                        + 0.5,
                    )

                # ğŸ¯ ì €ì¥ ì„ê³„ì¹˜ ì™„í™”: 1.0% â†’ 0.3%
                if (progress - last_saved_progress) >= 0.3:
                    processing_jobs[job_id]["status"] = "running"
                    processing_jobs[job_id]["progress"] = float(progress)
                    try:
                        db_upsert_job(processing_jobs[job_id])
                    except Exception as _e:
                        # ì§„í–‰ë¥  ì €ì¥ ì‹¤íŒ¨ê°€ ë¶„ì„ì„ ë§‰ì§€ ì•Šë„ë¡
                        pass
                    if on_progress:
                        try:
                            on_progress(progress)
                        except Exception:
                            pass
                    last_saved_progress = progress

            # ë‹¤ìŒ ì°½ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œ
            advanced = 0
            for _ in range(STRIDE):
                ok, fr = cap.read()
                if not ok:
                    break
                fr_orig = fr
                fr_small = cv2.resize(
                    fr_orig, (RESIZE_W, RESIZE_H), interpolation=cv2.INTER_AREA
                )
                buf_small.append(fr_small)
                buf_orig.append(fr_orig)
                advanced += 1
            frame_base_idx += STRIDE
            if advanced < STRIDE:
                break

        # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ â†’ gap flush(â‰¤2ì´ˆë©´ ë¶™ì—¬ì“°ê¸°) í›„ í´ë¦½ ë‹«ê¸°
        if active_clip is not None:
            if in_gap and len(gap_buf) <= tol_frames:
                for fr in gap_buf:
                    active_clip.write(fr)
            _close_clip()

        # writer/ìº¡ì³ ì •ë¦¬
        annot_writer.release()
        _faststart_remux(annotated_path)
        _encode_h264_faststart(annotated_path)
        cap.release()

        # ìµœì¢… ê²°ê³¼ (progress=100) - DB ì €ì¥ + ë™ì‹œì— return í•  ê°ì²´
        result_clips = clips_meta
        processing_jobs[job_id] = {
            "job_id": job_id,
            "status": "done",
            "progress": 100.0,
            "results": result_clips,
            "video_path": video_path,
            "annotated_video": annotated_path,
        }

        for c in clips_meta:
            bbox = c.get("start_bbox") or [None, None, None, None]
            x1, y1, x2, y2 = bbox
            clip = Clip(
                job_id=job_id,
                class_name=c["class_name"],  # âœ… ì¶”ê°€
                start_time=c["start_time"],
                start_x=x1,
                start_y=y1,
                start_w=(x2 - x1) if x1 is not None and x2 is not None else None,
                start_h=(y2 - y1) if y1 is not None and y2 is not None else None,
                clip_name=c["clip_name"],
                clip_path=c["clip_path"],
                thumbnail=c.get("thumbnail"),  # âœ… ì¶”ê°€
            )
            db.session.add(clip)

        db.session.commit()
        db_upsert_job(processing_jobs[job_id])

        # âœ… í˜¸ì¶œìì—ê²Œë„ ê²°ê³¼ë¥¼ ì¦‰ì‹œ ë°˜í™˜
        return {"ok": True, "results": result_clips}

    except Exception as e:
        err_job = {
            "job_id": job_id,
            "status": "error",
            "progress": float(processing_jobs.get(job_id, {}).get("progress", 0.0)),
            "results": None,
            "video_path": video_path,
            "message": str(e),  # â† error ëŒ€ì‹  message
        }
        processing_jobs[job_id] = err_job
        db_upsert_job(err_job)
        return {"ok": False, "error": str(e)}
